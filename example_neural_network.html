<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0080)http://my.safaribooksonline.com/print?xmlid=9780596529321%2Flearning_from_clicks -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><link rel="stylesheet" type="text/css" href="./example_neural_network_files/docsafarip.css"><link rel="stylesheet" type="text/css" href="./example_neural_network_files/getfile"><script type="text/javascript" src="chrome-extension://bfbmjmiodbnnpllbbbfblcplfjjepjdn/js/injected.js"></script><style type="text/css"></style></head><body><div><p class="p"></p><hr><strong class="strong">Username: </strong><span>Andrew Kim</span><span> </span><strong class="strong">Book: </strong><span>Programming Collective Intelligence. </span><span>No part of any chapter or book may be reproduced or transmitted in any form by any means without the prior written permission for reprints and excerpts from the publisher of the book or chapter. Redistribution or other use that violates the fair use privilege under U.S. copyright laws (see 17 USC107) or that otherwise violates these Terms of Service is strictly prohibited. Violators will be prosecuted to the full extent of U.S. Federal and Massachusetts laws.</span><hr><p></p><div id="HtmlView"><div><h1 class="epub__title"><a id="learning_from_clicks"></a>Learning from Clicks</h1>






<p>One of the major advantages of online applications is that they
      receive constant feedback in the form of user behavior. In the case of a
      search engine, each user will immediately provide information about how
      much he likes the results for a given search by clicking on one result
      and choosing not to click on the others. This section will look at a way
      to record when a user clicks on a result after a query, and how that
      record can be used to improve the rankings of the results.<a id="IDX-CHP-4-0260" class="epub__indexterm"></a><a id="IDX-CHP-4-0261" class="epub__indexterm"></a><a id="IDX-CHP-4-0262" class="epub__indexterm"></a></p>
<p>To do this, you’re going to build an <span class="epub__emphasis"><em>artificial neural
      network</em></span> that you’ll train by giving it the words in the
      query, the search results presented to the user, and what the user
      decided to click. Once the network has been trained with many different
      queries, you can use it to change the ordering of the search results to
      better reflect what users actually clicked on in the past.<a id="IDX-CHP-4-0263" class="epub__indexterm"></a></p>
<div class="epub__sect2" title="Design of a Click-Tracking Network"><div class="epub__titlepage"><div>
<div>
<h2 class="epub__title"><a id="design_of_a_clicktracking_network"></a>Design of a Click-Tracking Network</h2>
</div>

</div>


</div>
<p>While there are many different kinds of neural networks, they
        all consist of a set of nodes (the <span class="epub__emphasis"><em>neurons</em></span>) and
        connections between them. The network you’ll learn how to build is
        called a <span class="epub__emphasis"><em>multilayer perceptron</em></span> (MLP) network.
        This type of network consists of multiple layers of neurons, the first
        of which takes the input—in this case, the words entered by the user.
        The last layer gives the output, which in this example is a list of
        weightings for the different URLs that were returned.</p>
<p>There can be multiple middle layers, but the network in this
        example will just use a single one. This is called the
        <span class="epub__emphasis"><em>hidden layer</em></span> because the outside world never
        interacts with it directly, and it responds to combinations of inputs.
        In this case, a combination of inputs is a set of words, so you could
        also think of this as the <span class="epub__emphasis"><em>query layer</em></span>. <a href="http://my.safaribooksonline.com/9780596529321/learning_from_clicks#design_of_a_clicktracking_neural_network" class="epub__xref" title="Figure 4-4. Design of a click-tracking neural network" data-ajax="1">Figure&nbsp;4-4</a> shows the
        structure of the network. All the nodes in the input layer are
        connected to all the nodes in the hidden layer, and all the nodes in
        the hidden layer are connected to all the nodes in the output
        layer.<a id="IDX-CHP-4-0264" class="epub__indexterm"></a></p><div class="epub__figure"><a id="design_of_a_clicktracking_neural_network"></a><div class="epub__figure-contents"><div class="epub__mediaobject"><a id="I_mediaobject4_tt139"></a><img src="./example_neural_network_files/getfile(1)" alt="Design of a click-tracking neural network">
</div>

</div>


<p class="epub__title">Figure&nbsp;4-4.&nbsp;Design of a click-tracking neural network</p>
</div>
<p>To ask the neural network to get the best results for a query,
        the input nodes for the words in that query have their values set to
        1. The outputs of those nodes are turned on and they attempt to
        activate the hidden layer. In turn, the nodes in the hidden layer that
        get a strong enough input will turn on their outputs and try to
        activate nodes in the output layer.</p>
<p>The nodes in the output layer then become active in various
        degrees, and their activity level can be used to determine how
        strongly a URL is associated with the words in the original query.
        <a href="http://my.safaribooksonline.com/9780596529321/learning_from_clicks#neural_network_response_to_world_bank" class="epub__xref" title="Figure 4-5. Neural network response to “world bank”" data-ajax="1">Figure&nbsp;4-5</a> shows a query
        for “world bank.” The solid lines indicate strong connections, and the
        bold text indicates that a node has become very active.</p><div class="epub__figure"><a id="neural_network_response_to_world_bank"></a><div class="epub__figure-contents"><div class="epub__mediaobject"><a id="I_mediaobject4_tt140"></a><img src="./example_neural_network_files/getfile(2)" alt="Neural network response to “world bank”">
</div>

</div>


<p class="epub__title">Figure&nbsp;4-5.&nbsp;Neural network response to “world bank”</p>
</div>
<p>This, of course, depends on the connection strengths being
        correct. This is achieved by <span class="epub__emphasis"><em>training</em></span> the network
        every time someone performs a search and chooses one of the links out
        of the results. In the network pictured in <a href="http://my.safaribooksonline.com/9780596529321/learning_from_clicks#neural_network_response_to_world_bank" class="epub__xref" title="Figure 4-5. Neural network response to “world bank”" data-ajax="1">Figure&nbsp;4-5</a>, a number of people
        had previously clicked the World Bank result after a search for “world
        bank,” and this strengthened the associations between the words and
        the URL. This section will show you how the network is trained with an
        algorithm called <code class="epub__literal">backpropagation</code>.</p>
<p>You might be wondering why you would need a sophisticated
        technique like a neural network instead of just remembering the query
        and counting how many times each result was clicked. The power of the
        neural network you’re going to build is that it can make reasonable
        guesses about results for queries it has never seen before, based on
        their similarity to other queries. Also, neural networks are useful
        for a wide variety of applications and will be a great addition to
        your collective intelligence toolbox.</p>
</div>
<div class="epub__sect2" title="Setting Up the Database"><div class="epub__titlepage"><div>
<div>
<h2 class="epub__title"><a id="setting_up_the_database"></a>Setting Up the Database</h2>
</div>

</div>


</div>
<p>Since the neural network will have to be trained over time as
        users perform queries, you’ll need to store a representation of the
        network in the database. The database already has a table of words and
        URLs, so all that’s needed is a table for the hidden layer (which will
        be called <code class="epub__literal">hiddennode</code>) and two
        tables of connections (one from the word layer to the hidden layer,
        and one that links the hidden layer to the output layer).<a id="IDX-CHP-4-0265" class="epub__indexterm"></a><a id="IDX-CHP-4-0266" class="epub__indexterm"></a><a id="IDX-CHP-4-0267" class="epub__indexterm"></a><a id="IDX-CHP-4-0268" class="epub__indexterm"></a><a id="IDX-CHP-4-0269" class="epub__indexterm"></a></p>
<p>Create a new file called <em class="epub__filename">nn.py</em>, and create a new class in it called
        <code class="epub__literal">searchnet</code>:</p><a id="I_programlisting4_tt141"></a>
<pre class="epub__programlisting">from math import tanh
from pysqlite2 import dbapi2 as sqlite

class searchnet:
    def __init_  _(self,dbname):
      self.con=sqlite.connect(dbname)

    def __del_  _(self):
      self.con.close(  )

    def maketables(self):
      self.con.execute('create table hiddennode(create_key)')
      self.con.execute('create table wordhidden(fromid,toid,strength)')
      self.con.execute('create table hiddenurl(fromid,toid,strength)')
      self.con.commit(  )</pre>
<p>The tables currently have no indices, but you can add them later
        if speed is an issue.</p>
<p>You’ll need to create a couple of methods to access the
        database. The first method, called <code class="epub__literal">getstrength</code>, determines the current strength
        of a connection. Because new connections are only created when
        necessary, this method has to return a default value if there are no
        connections. For links from words to the hidden layer, the default
        value will be −0.2 so that, by default, extra words will have a
        slightly negative effect on the activation level of a hidden node. For
        links from the hidden layer to URLs, the method will return a default
        value of 0.</p><a id="I_programlisting4_tt142"></a>
<pre class="epub__programlisting">    def getstrength(self,fromid,toid,layer):
      if layer==0: table='wordhidden'
      else: table='hiddenurl'
      res=self.con.execute('select strength from %s where fromid=%d and toid=%d' %
(table,fromid,toid)).fetchone(  )
      if res==None:
          if layer==0: return −0.2
          if layer==1: return 0
      return res[0]</pre>
<p>You’ll also need a <code class="epub__literal">setstrength</code> method to determine if a
        connection already exists, and to update or create the connection with
        the new strength. This will be used by the code that trains the
        network:</p><a id="I_programlisting4_tt143"></a>
<pre class="epub__programlisting">    def setstrength(self,fromid,toid,layer,strength):
      if layer==0: table='wordhidden'
      else: table='hiddenurl'
      res=self.con.execute('select rowid from %s where fromid=%d and toid=%d' %
(table,fromid,toid)).fetchone(  )
      if res==None:
        self.con.execute('insert into %s (fromid,toid,strength) values (%d,%d,%f)' %
(table,fromid,toid,strength))
      else:
        rowid=res[0]
        self.con.execute('update %s set strength=%f where rowid=%d' % (table,
strength,rowid))</pre>
<p>Most of the time, when building a neural network, all the nodes
        in the network are created in advance. You could create a huge network
        up front with thousands of nodes in the hidden layer and all the
        connections already in place, but in this case, it will be faster and
        simpler to create new hidden nodes as they are needed.</p>
<p>This function will create a new node in the hidden layer every
        time it is passed a combination of words that it has never seen
        together before. The function then creates default-weighted links
        between the words and the hidden node, and between the query node and
        the URL results returned by this query.</p><a id="I_programlisting4_tt144"></a>
<pre class="epub__programlisting">    def generatehiddennode(self,wordids,urls):
      if len(wordids)&gt;3: return None
      # Check if we already created a node for this set of words
      createkey='_'.join(sorted([str(wi) for wi in wordids]))
      res=self.con.execute(
      "select rowid from hiddennode where create_key='%s'" % createkey).fetchone(  )

      # If not, create it
      if res==None:
        cur=self.con.execute(
        "insert into hiddennode (create_key) values ('%s')" % createkey)
        hiddenid=cur.lastrowid
        # Put in some default weights
        for wordid in wordids:
          self.setstrength(wordid,hiddenid,0,1.0/len(wordids))
        for urlid in urls:
          self.setstrength(hiddenid,urlid,1,0.1)
        self.con.commit(  )</pre>
<p>In the Python interpreter, try creating a database and
        generating a hidden node with some example word and URL IDs:</p><a id="I_programlisting4_tt145"></a>
<pre class="epub__programlisting">&gt;&gt;<strong class="epub__userinput"><code>import nn</code></strong>
<strong class="epub__userinput"><code>&gt;&gt; mynet=nn.searchnet('nn.db')</code></strong>
<strong class="epub__userinput"><code>&gt;&gt; mynet.maketables(  )</code></strong>
<strong class="epub__userinput"><code>&gt;&gt; wWorld,wRiver,wBank =101,102,103</code></strong>
<strong class="epub__userinput"><code>&gt;&gt; uWorldBank,uRiver,uEarth =201,202,203</code></strong>
<strong class="epub__userinput"><code>&gt;&gt; mynet.generatehiddennode([wWorld,wBank],[uWorldBank,uRiver,uEarth])</code></strong>
<strong class="epub__userinput"><code>&gt;&gt; for c in mynet.con.execute('select * from wordhidden'): print c</code></strong>
(101, 1, 0.5)
(103, 1, 0.5)
&gt;&gt; <strong class="epub__userinput"><code>for c in mynet.con.execute('select * from hiddenurl'): print c</code></strong>
(1, 201, 0.1)
(1, 202, 0.1)
...</pre>
<p>A new node has been created in the hidden layer, and links to
        the new node have been created with default values. The function will
        initially respond whenever “world” and “bank” are entered together,
        but these connections may weaken over time.</p>
</div>
<div class="epub__sect2" title="Feeding Forward"><div class="epub__titlepage"><div>
<div>
<h2 class="epub__title"><a id="feeding_forward"></a>Feeding Forward</h2>
</div>

</div>


</div>
<p>You’re now ready to make functions that will take the words as
        inputs, activate the links in the network, and give a set of outputs
        for the URLs.<a id="IDX-CHP-4-0270" class="epub__indexterm"></a><a id="IDX-CHP-4-0271" class="epub__indexterm"></a><a id="IDX-CHP-4-0272" class="epub__indexterm"></a><a id="IDX-CHP-4-0273" class="epub__indexterm"></a></p>
<p>First, choose a function that indicates how much each node
        should respond to its input. The neural network described here will
        use the <span class="epub__emphasis"><em>hyperbolic tangent</em></span> (<code class="epub__literal">tanh</code>) function, shown in <a href="http://my.safaribooksonline.com/9780596529321/learning_from_clicks#the_tanh_function" class="epub__xref" title="Figure 4-6. The tanh function" data-ajax="1">Figure&nbsp;4-6</a>.</p><div class="epub__figure"><a id="the_tanh_function"></a><div class="epub__figure-contents"><div class="epub__mediaobject"><a id="I_mediaobject4_tt146"></a><img src="./example_neural_network_files/getfile(3)" alt="The tanh function">
</div>

</div>


<p class="epub__title">Figure&nbsp;4-6.&nbsp;The tanh function</p>
</div>
<p>The x-axis is the total input to the node. As the input
        approaches 0, the output starts to climb quickly. With an input of 2,
        the output is almost at 1 and doesn’t get much higher. This is a type
        of <span class="epub__emphasis"><em>sigmoid</em></span> function, all types of which have this
        S shape. Neural networks almost always use sigmoid functions to
        calculate the outputs of the neurons.</p>
<p>Before running the <code class="epub__literal">feedforward</code> algorithm, the class will have
        to query the nodes and connections in the database, and build, in
        memory, the portion of the network that is relevant to a specific
        query. The first step is to create a function that finds all the nodes
        from the hidden layer that are relevant to a specific query—in this
        case, they must be connected to one of the words in the query or to
        one of the URLs in the results. Since the other nodes will not be used
        either to determine an outcome or to train the network, it’s not
        necessary to include them:</p><a id="I_programlisting4_tt147"></a>
<pre class="epub__programlisting">    def getallhiddenids(self,wordids,urlids):
      l1={}
      for wordid in wordids:
        cur=self.con.execute(
        'select toid from wordhidden where fromid=%d' % wordid)
        for row in cur: l1[row[0]]=1
      for urlid in urlids:
        cur=self.con.execute(
        'select fromid from hiddenurl where toid=%d' % urlid)
        for row in cur: l1[row[0]]=1
      return l1.keys(  )</pre>
<p>You will also need a method for constructing the relevant
        network with all the current weights from the database. This function
        sets a lot of instance variables for this class—the list of words,
        query nodes and URLs, the output level of every node, and the weights
        of every link between nodes. The weights are taken from the database
        using the functions that were defined earlier.</p><a id="I_programlisting4_tt148"></a>
<pre class="epub__programlisting">    def setupnetwork(self,wordids,urlids):
        # value lists
        self.wordids=wordids
        self.hiddenids=self.getallhiddenids(wordids,urlids)
        self.urlids=urlids

        # node outputs
        self.ai = [1.0]*len(self.wordids)
        self.ah = [1.0]*len(self.hiddenids)
        self.ao = [1.0]*len(self.urlids)

        # create weights matrix
        self.wi = [[self.getstrength(wordid,hiddenid,0)
                    for hiddenid in self.hiddenids]
                   for wordid in self.wordids]
        self.wo = [[self.getstrength(hiddenid,urlid,1)
                    for urlid in self.urlids]
                   for hiddenid in self.hiddenids]</pre>
<p>You’re finally ready to create the <code class="epub__literal">feedforward</code> algorithm. This takes a list of
        inputs, pushes them through the network, and returns the output of all
        the nodes in the output layer. In this case, since you’ve only
        constructed a network with words in the query, the output from all the
        input nodes will always be 1:</p><a id="I_programlisting4_tt149"></a>
<pre class="epub__programlisting">    def feedforward(self):
        # the only inputs are the query words
        for i in range(len(self.wordids)):
            self.ai[i] = 1.0

        # hidden activations
        for j in range(len(self.hiddenids)):
            sum = 0.0
            for i in range(len(self.wordids)):
                sum = sum + self.ai[i] * self.wi[i][j]
            self.ah[j] = tanh(sum)

        # output activations
        for k in range(len(self.urlids)):
            sum = 0.0
            for j in range(len(self.hiddenids)):
                sum = sum + self.ah[j] * self.wo[j][k]
            self.ao[k] = tanh(sum)

        return self.ao[:]</pre>
<p>The <code class="epub__literal">feedforward</code> algorithm
        works by looping over all the nodes in the hidden layer and adding
        together all the outputs from the input layer multiplied by the
        strengths of the links. The output of each node is the <code class="epub__literal">tanh</code> function of the sum of all the inputs,
        which is passed on to the output layer. The output layer does the same
        thing, multiplying the outputs of the previous layer by their
        strengths, and applies the <code class="epub__literal">tanh</code>
        function to produce the final output. It is easy to extend the network
        to have more layers by continually using the output of one layer as
        the input to the next layer.</p>
<p>Now you can write a short function that will set up the network
        and use <code class="epub__literal">feedforward</code> to get the
        outputs for a set of words and URLs:</p><a id="I_programlisting4_tt150"></a>
<pre class="epub__programlisting">    def getresult(self,wordids,urlids):
      self.setupnetwork(wordids,urlids)
      return self.feedforward(  )</pre>
<p>You can use Python to try this in the network:</p><a id="I_programlisting4_tt151"></a>
<pre class="epub__programlisting">&gt;&gt;<strong class="epub__userinput"><code>reload(nn)</code></strong>
<strong class="epub__userinput"><code>&gt;&gt; mynet=nn.searchnet('nn.db')</code></strong>
<strong class="epub__userinput"><code>&gt;&gt; mynet.getresult([wWorld,wBank],[uWorldBank,uRiver,uEarth])</code></strong>
[0.076,0.076,0.76]</pre>
<p>The numbers in the returned list correspond to the relevance of
        the input URLs. Not surprisingly, because it hasn’t yet had any
        training, the neural network gives the same answer for every
        URL.</p>
</div>
<div class="epub__sect2" title="Training with Backpropagation"><div class="epub__titlepage"><div>
<div>
<h2 class="epub__title"><a id="training_with_backpropagation"></a>Training with Backpropagation</h2>
</div>

</div>


</div>
<p>Here’s where things get interesting. The network will take
        inputs and give outputs, but because it hasn’t been taught what a good
        result looks like, the results are pretty useless. You’re now going to
        train the network by showing it some actual examples of what people
        searched for, which results were returned, and what the users decided
        to click on.<a id="IDX-CHP-4-0274" class="epub__indexterm"></a><a id="IDX-CHP-4-0275" class="epub__indexterm"></a><a id="IDX-CHP-4-0276" class="epub__indexterm"></a></p>
<p>For this to work, you need an algorithm that alters the weights
        of the links between the nodes to better reflect what the network is
        being told is the right answer. The weights have to be adjusted slowly
        because you can’t assume that the each user will click on an answer
        that’s appropriate for everyone. The algorithm you’ll use is called
        <span class="epub__emphasis"><em>backpropagation</em></span> because it moves backward through
        the network adjusting the weights.<a id="IDX-CHP-4-0277" class="epub__indexterm"></a><a id="IDX-CHP-4-0278" class="epub__indexterm"></a></p>
<p>When training a network, you always know the desired output of
        each node in the output layer. In this case, it should be pushed
        toward 1 if the user clicked on that result, and pushed toward 0 if he
        did not. The only way to change the output of a node is to change the
        total input to that node.</p>
<p>To determine how much the total input should be changed, the
        training algorithm has to know the slope of the <code class="epub__literal">tanh</code> function at its current level of
        output. In the middle of the function, when the output is 0.0, the
        slope is very steep, so changing the input by only a small amount
        gives a big change. As the outputs get closer to −1 or 1, changing the
        input has a smaller effect on the output. The slope of the function
        for any output value is specified by this function, which you can add
        to the start of <em class="epub__filename">nn.py</em>:</p><a id="I_programlisting4_tt152"></a>
<pre class="epub__programlisting">def dtanh(y):
    return 1.0−y*y</pre>
<p>Before running the backpropagation method, it’s necessary to run
        <code class="epub__literal">feedforward</code> so that the current
        output of every node will be stored in the instance variables. The
        backpropagation algorithm then performs the following steps.</p>
<p>For each node in the output layer:</p><div class="epub__orderedlist">
<ol class="epub__orderedlist">
<li class="epub__listitem">
<p>Calculate the difference between the node’s current output
            and what it should be.</p></li><li class="epub__listitem">
<p>Use the <code class="epub__literal">dtanh</code> function to
            determine how much the node’s total input has to change.</p></li><li class="epub__listitem">
<p>Change the strength of every incoming link in proportion to
            the link’s current strength and the learning rate.</p></li></ol>

</div>
<p>For each node in the hidden layer:</p><div class="epub__orderedlist">
<ol class="epub__orderedlist">
<li class="epub__listitem">
<p>Change the output of the node by the sum of the strength of
            each output link multiplied by how much its target node has to
            change.</p></li><li class="epub__listitem">
<p>Use the <code class="epub__literal">dtanh</code> function to
            determine how much the node’s total input has to change.</p></li><li class="epub__listitem">
<p>Change the strength of every input link in proportion to the
            link’s current strength and the learning rate.</p></li></ol>

</div>
<p>The implementation of this algorithm actually calculates all the
        errors in advance and then adjusts the weights, because all the
        calculations rely on knowing the current weights rather than the
        updated weights. Here’s the code for the algorithm, which you can add
        to the <code class="epub__literal">searchnet</code> class:</p><a id="I_programlisting4_tt153"></a>
<pre class="epub__programlisting">    def backPropagate(self, targets, N=0.5):
        # calculate errors for output
        output_deltas = [0.0] * len(self.urlids)
        for k in range(len(self.urlids)):
            error = targets[k]−self.ao[k]
            output_deltas[k] = dtanh(self.ao[k]) * error

        # calculate errors for hidden layer
        hidden_deltas = [0.0] * len(self.hiddenids)
        for j in range(len(self.hiddenids)):
            error = 0.0
            for k in range(len(self.urlids)):
                error = error + output_deltas[k]*self.wo[j][k]
            hidden_deltas[j] = dtanh(self.ah[j]) * error
        # update output weights
        for j in range(len(self.hiddenids)):
            for k in range(len(self.urlids)):
                change = output_deltas[k]*self.ah[j]
                self.wo[j][k] = self.wo[j][k] + N*change

        # update input weights
        for i in range(len(self.wordids)):
            for j in range(len(self.hiddenids)):
                change = hidden_deltas[j]*self.ai[i]
                self.wi[i][j] = self.wi[i][j] + N*change</pre>
<p>Now all you need is a simple method that will set up the
        network, run <code class="epub__literal">feedforward</code>, and run
        the backpropagation. This method takes the list of <code class="epub__literal">wordids</code>, <code class="epub__literal">urlids</code>, and a selected URL:</p><a id="I_programlisting4_tt154"></a>
<pre class="epub__programlisting">    def trainquery(self,wordids,urlids,selectedurl):
      # generate a hidden node if necessary
      self.generatehiddennode(wordids,urlids)

      self.setupnetwork(wordids,urlids)
      self.feedforward(  )
      targets=[0.0]*len(urlids)
      targets[urlids.index(selectedurl)]=1.0
      self.backPropagate(targets)
      self.updatedatabase(  )</pre>
<p>To save the results, you’ll also need a method to update the
        database with the new weights, which are stored in the <code class="epub__literal">wi</code> and <code class="epub__literal">wo</code>
        instance variables:</p><a id="I_programlisting4_tt155"></a>
<pre class="epub__programlisting">    def updatedatabase(self):
      # set them to database values
      for i in range(len(self.wordids)):
          for j in range(len(self.hiddenids)):
              self.setstrength(self.wordids[i],self. hiddenids[j],0,self.wi[i][j])
      for j in range(len(self.hiddenids)):
          for k in range(len(self.urlids)):
              self.setstrength(self.hiddenids[j],self.urlids[k],1,self.wo[j][k])
      self.con.commit(  )</pre>
<p>Now you can do a simple test with the query you tried earlier to
        see how the network responds to training:</p><a id="I_programlisting4_tt156"></a>
<pre class="epub__programlisting">&gt;&gt;<strong class="epub__userinput"><code>reload(nn)</code></strong>
<strong class="epub__userinput"><code>&gt;&gt; mynet=nn.searchnet('nn.db')</code></strong>
<strong class="epub__userinput"><code>&gt;&gt; mynet.trainquery([wWorld,wBank],[uWorldBank,uRiver,uEarth],uWorldBank)</code></strong>
<strong class="epub__userinput"><code>&gt;&gt; mynet.getresult([wWorld,wBank],[uWorldBank,uRiver,uEarth])</code></strong>
[0.335,0.055,0.055]</pre>
<p>The output for the World Bank URL increased and the output for
        the other URLs decreased after the network learned that a particular
        user made that selection. The more users make this selection, the
        bigger the difference will get.</p>
</div>
<div class="epub__sect2" title="Training Test"><div class="epub__titlepage"><div>
<div>
<h2 class="epub__title"><a id="training_test"></a>Training Test</h2>
</div>

</div>


</div>
<p>So far you’ve seen that training with one sample result
        increases the output for that result. Although that’s useful, it
        doesn’t really demonstrate what neural networks are capable of—that
        is, reasoning about inputs they’ve never seen before. Try this code in
        your interactive Python session:<a id="IDX-CHP-4-0279" class="epub__indexterm"></a><a id="IDX-CHP-4-0280" class="epub__indexterm"></a><a id="IDX-CHP-4-0281" class="epub__indexterm"></a><a id="IDX-CHP-4-0282" class="epub__indexterm"></a></p><a id="I_programlisting4_tt157"></a>
<pre class="epub__programlisting">&gt;&gt;<strong class="epub__userinput"><code>allurls=[uWorldBank,uRiver,uEarth]</code></strong>
<strong class="epub__userinput"><code>&gt;&gt; for i in range(30):</code></strong>
<strong class="epub__userinput"><code>...     mynet.trainquery([wWorld,wBank],allurls,uWorldBank)</code></strong>
<strong class="epub__userinput"><code>...     mynet.trainquery([wRiver,wBank],allurls,uRiver)</code></strong>
<strong class="epub__userinput"><code>...     mynet.trainquery([wWorld],allurls,uEarth)</code></strong>
...
&gt;&gt; <strong class="epub__userinput"><code>mynet.getresult([wWorld,wBank],allurls)</code></strong>
[0.861, 0.011, 0.016]
&gt;&gt; <strong class="epub__userinput"><code>mynet.getresult([wRiver,wBank],allurls)</code></strong>
[-0.030, 0.883, 0.006]
&gt;&gt; <strong class="epub__userinput"><code>mynet.getresult([wBank],allurls)</code></strong>
[0.865, 0.001, −0.85]</pre>
<p>Even though the network has never seen a query for “bank” by
        itself before, it gives a reasonable guess. Not only that, it gives
        the World Bank URL a much better score than the River URL, even though
        in the training sample queries “bank” was associated just as often
        with “river” as it was with World Bank. The network has not only
        learned which URLs are related to which queries, it has also learned
        what the important words are in a particular query—something that
        could not have been achieved with a simple query-URL
        correlation.</p>
</div>
<div class="epub__sect2" title="Connecting to the Search Engine"><div class="epub__titlepage"><div>
<div>
<h2 class="epub__title"><a id="connecting_to_the_search_engine"></a>Connecting to the Search Engine</h2>
</div>

</div>


</div>
<p>The <code class="epub__literal">query</code> method of the
        <code class="epub__literal">searcher</code> class gets a list of URL
        IDs and word IDs in the course of creating and printing the results.
        You can have the method return these results by adding the following
        line to the end of the <code class="epub__literal">query</code> in
        <em class="epub__filename">searchengine.py</em>:</p><a id="I_programlisting4_tt158"></a>
<pre class="epub__programlisting">    return wordids,[r[1] for r in rankedscores[0:10]]</pre>
<p>These can be passed directly to the <code class="epub__literal">trainquery</code> method of <code class="epub__literal">searchnet</code>.</p>
<p>The method for capturing which of the results the user liked
        best is specific to the design of your application. It’s possible that
        a web page could include an intermediate page that captures the click
        and calls <code class="epub__literal">trainquery</code> before
        redirecting to the actual search, or you could even let users vote on
        the relevance of search results to help improve your algorithm.</p>
<p>The final step in building the artificial neural network is
        creating a new method in the <code class="epub__literal">searcher</code> class to allow you to weight the
        results. This function looks pretty similar to the other weighting
        functions. The first thing you’ll need to do is import the neural
        network class in <em class="epub__filename">searchengine.py</em>:</p><a id="I_programlisting4_tt159"></a>
<pre class="epub__programlisting">import nn
mynet=nn.searchnet('nn.db')</pre>
<p>And add this method to the <code class="epub__literal">searcher</code> class:</p><a id="I_programlisting4_tt160"></a>
<pre class="epub__programlisting">  def nnscore(self,rows,wordids):
    # Get unique URL IDs as an ordered list
    urlids=[urlid for urlid in set([row[0] for row in rows])]
    nnres=mynet.getresult(wordids,urlids)
    scores=dict([(urlids[i],nnres[i]) for i in range(len(urlids))])
    return self.normalizescores(scores)</pre>
<p>Again, you can experiment by including this in your <code class="epub__literal">weights</code> list with various weights. In
        practice, it’s better to hold off on including it as part of your
        scoring until the network has been trained on a large number of
        different examples.</p>
<p>This chapter has covered a wide range of possibilities for
        developing a search engine, but it’s still very limited compared to
        what’s possible. The exercises will explore some further ideas. This
        chapter has not focused on performance—which would require work to
        index millions of pages—but what you’ve built will perform adequately
        on a set of 100,000 pages, enough for a news site or corporate
        intranet.<a id="IDX-CHP-4-0283" class="epub__indexterm"></a></p>
</div>



<div class="epub__sect1" title="Exercises"><div class="epub__titlepage"><div>
<div>
</div>
</div>
</div>
</div>
</div>
</div><script type="text/javascript">
function PagePrint()
{
    setTimeout("window.print()", 500);
}
PagePrint();
</script></div><span id="BowEndOfDocument" style="display:none" hidden="hidden"></span></body></html>